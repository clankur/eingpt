{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clankur/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model import GptLanguageModel\n",
    "from common import GptConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = GptConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GptLanguageModel(hyperparameters)\n",
    "weights_file = 'model_weights_900k_steps.pth'\n",
    "model.load_state_dict(torch.load(weights_file, map_location=model.device))\n",
    "m = model.to(model.device)\n",
    "tokenizer = m.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_str = \"\"\"Once upon a time there was a pumpkin. It was a very special pumpkin, it could speak. \n",
    "It was sad because it couldn't move. Every day, it would say\"\"\"\n",
    "encoded_input = tokenizer.encode(start_str)\n",
    "idx = torch.tensor(encoded_input, dtype=torch.long, device=model.device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a pumpkin. It was a very special pumpkin, it could speak. \n",
      "It was sad because it couldn't move. Every day, it would say goodbye and be safe and safe to others.  It never got lost.\n",
      "It always remembered that it was about being brave, like a big pumpkin, who lived on it! Every time he was very careful when she played and make sure everyone around the flower. They laughed so high, and it always stayed safe forever forever forever in the future - it was the best day to have fun with the pumpkin! The end!\n",
      "And it and the pumpkin were the most happy, so lucky to have someone else a safe world around it together and the sun.   It knew that the best day of being kind and helping people could be safe and safe and help everyone. \n",
      "\n",
      " the town knew it was very good to have something new. They were the best way and they all knew the day to be friends and never let the flower come away again and no more knew how much they had to worry. And the end was no longer lonely because of being kind to each other! The pumpkin and its friends stayed friends for days, until their day was over to have lots. The pumpkin learned\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(m.generate(idx = idx, max_new_tokens=model.block_size-len(encoded_input))[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9999, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from common import TinyStoriesLoader, compute_perplexity\n",
    "validation_set = TinyStoriesLoader(hyperparameters, split='validation')\n",
    "compute_perplexity(m, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained('roneneldan/TinyStories-33M')\n",
    "validation_set = TinyStoriesLoader(hyperparameters, split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix loading input_ids into model\n",
    "# compute_perplexity(model, validation_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
