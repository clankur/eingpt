{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NanoGPTLangugageModel as nano\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nano.NanoGPTLanguageModel()\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "m = model.to(nano.device)\n",
    "encode, decode = nano.encode, nano.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Togerous before them, after would those thrifts;\n",
      "Yield these have I look not how they there is no.\n",
      "Come, let's upon the desire\n",
      "Be count in affection. My noble looking throw\n",
      "Grows all.\n",
      "\n",
      "Lord:\n",
      "We thank that Paris to him.\n",
      "\n",
      "FLORIZEL:\n",
      "For child, be but long.\n",
      "\n",
      "P\n"
     ]
    }
   ],
   "source": [
    "start_str = \"\\n\"\n",
    "idx = torch.tensor(encode(start_str), dtype=torch.long, device=device).unsqueeze(0)\n",
    "print(decode(m.generate(idx = idx, max_new_tokens=256)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from einops import rearrange, einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix mult using einsum w/ B H T D tensor\n",
    "torch.manual_seed(1337)\n",
    "B, H, T, D = 1, 3, 4, 3\n",
    "out = torch.randint(-10, 10, (B, H, T, D)) # (B, H, T, D)\n",
    "out_proj = torch.randint(-10, 10, (H, D, H*D)) # (H, D, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-154,  224,  175,   75,  -45,   15,  224,  -18, -100],\n",
       "         [-118,   61,   -8,  180,  -28,   -3,  -33,  -33,  -73],\n",
       "         [ 137, -124,  -38,  -95,  -55,   49, -115,  113,   70],\n",
       "         [  97,    7, -171,   -8,   91,   64,  123, -133, -206]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_proj_T = rearrange(out_proj, 'h d c -> c h d') # this isn't transpose, how to transpose\n",
    "einsum(out, out_proj_T, 'b h t d, c h d -> b t c') # (B, H, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  49,  -97,   53,   34, -107, -146,  158,  -85,  -36],\n",
       "          [ -72,  200,  -70,  175, -162, -143, -112, -187,    6],\n",
       "          [  91,   55,  -38,   38,   30,   39,  -87,   61,   -4],\n",
       "          [  50,   18,   86, -165,   72,  210,  146,  -25, -115]]]),\n",
       " tensor([[[True, True, True, True, True, True, True, True, True],\n",
       "          [True, True, True, True, True, True, True, True, True],\n",
       "          [True, True, True, True, True, True, True, True, True],\n",
       "          [True, True, True, True, True, True, True, True, True]]]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_out = rearrange(out, 'b h t d -> b t (h d)') # (B, T, C)\n",
    "new_out_proj = rearrange(out_proj, 'h d c -> (h d) c') # (C, C)\n",
    "new_out_proj_T = new_out_proj.T\n",
    "\n",
    "expected = F.linear(new_out, new_out_proj, bias=None) # (B, T, C)\n",
    "actual = einsum(new_out, new_out_proj_T, 'b t c1, c1 c2  -> b t c2') # (B, T, C)\n",
    "actual, expected == actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -1,  -2,  -7,  -4,   9,  -5,  -8,   4,  -9,   5,  -7,   0,   3,  -6,\n",
       "            4, -10,  -3,   8,  -3,  -5,   6,  -6, -10,  -6,  -3,  -8,   7,  -2,\n",
       "            6,  -7,  -2,  -6,   4,  -4,  -3,  -8],\n",
       "         [  4,   9,  -9,  -7, -10,   4,   4,   7,  -8,  -7,  -4,   4,   7,   6,\n",
       "           -4,   7,   0,  -9,  -1,   2,  -5,   7,   8,  -6,  -9,  -1,   6,  -9,\n",
       "            8,   0,  -9,   0,  -4,   9,   1,   5],\n",
       "         [  9,  -7,   1,  -1,  -2,   9, -10,   8,  -8,   2,   3,   5,  -8,  -1,\n",
       "           -9,   3,   0,  -7,   3,   6,  -6,  -3,  -3,   1,   5,  -8,   2,   5,\n",
       "           -3,  -3,  -1, -10,   7,   0,  -7,  -4],\n",
       "         [ -6,  -3,  -8,   2,  -2,   5,   3,  -2,  -2,   2,  -5,  -3,   0,  -3,\n",
       "           -2,  -2,  -5,  -1,   4,   3,  -6,   3,   5, -10,   8,   1,   6,   8,\n",
       "           -9,  -9,   1,   2,  -3,  -2,   1,  -4],\n",
       "         [ -4,   5,  -6,  -9,   7,  -1,  -3,  -6,  -6,  -1,  -8,   3,   7,   1,\n",
       "            6,   4,   7,  -8,  -3,  -7,   9,   9,   4,   3,  -8,  -9,   7,  -7,\n",
       "           -5,   7,   8, -10,   4,  -8,  -8,   5],\n",
       "         [ -4,  -1,   1,   1,   4,   0,  -6, -10,   6,  -7,  -9,  -5,   9,   6,\n",
       "            6,   8,   9,   6,  -7,  -6,  -6,  -9,  -5,  -1,   9,   6,   5, -10,\n",
       "            2,   9,  -1,   8,  -3,   5,  -8,  -2],\n",
       "         [ -3, -10,   8,   8,  -7,  -2,  -7,   3,   5,   2, -10,   4,   8,  -7,\n",
       "            8,   8,   3,   7,   8,  -2,  -6,  -3,   0,   0,   6,   5,  -4,  -9,\n",
       "            8,   8,  -6,  -3,  -9,  -1,   0,   2],\n",
       "         [  7,  -8,  -2,  -8,   5,   1,   2,   5,  -5,   7,   4,  -6,  -1,   2,\n",
       "           -4,  -8,  -1,   0, -10,  -3,   4,   9,  -6,   7,  -9,   6,  -5,   8,\n",
       "            3,   6,   1,  -8,  -1,  -2,   7,  -8],\n",
       "         [ -4, -10,   1,   5,  -3,  -3,  -8,  -8,   5,  -2,   2,   8,  -5, -10,\n",
       "            4,  -8,  -4,   7,  -3,  -3,   7,   3,   0,  -2,  -2,  -8,   4,   7,\n",
       "           -7,  -7,  -9,  -2,   3,   5,   3,   9]]),\n",
       " tensor([[  1,  -7,  -1,  -1,   7,   6,   2,  -6,  -3],\n",
       "         [-10,  -5,  -3,  -4,  -8,  -2,  -2,  -1,  -4],\n",
       "         [  0,   1,   9,  -3,   3,  -9,   5,   8,   0],\n",
       "         [  1,  -3,  -6,  -7,  -7,   8,  -3,   9,  -9],\n",
       "         [-10,   9,  -6,   9,  -4,   8,  -2,   3,  -2],\n",
       "         [  9,  -9,   5,   9,   2,  -1,  -4,   5,   0],\n",
       "         [  6,   4,   2,  -7,   2,   4,   1,   4,   3],\n",
       "         [  2,   4,  -2,   0,   5,  -8,   2,  -5,  -9],\n",
       "         [  1,   3,   3,   3,   6,   3,   9,  -1,   9],\n",
       "         [ -6,   7,  -9,  -4,   7,   2,   2,   0,   7],\n",
       "         [  7,  -3,   8,  -2,   0,   3,   9,  -4,  -4],\n",
       "         [  7,  -1,  -4,  -7,  -6,  -9,   1,   7,  -9],\n",
       "         [  7, -10,  -1,   3,   7,  -7,  -1,   0, -10],\n",
       "         [ -2,  -8,   4,   3,  -2,  -1,   5, -10,  -6],\n",
       "         [  6, -10,   6,  -7,   5,   4,  -7,  -2,  -6],\n",
       "         [ -4,  -2, -10,   3,   8,  -2,   5,  -4,  -3],\n",
       "         [  5,  -9,   6,   6,  -1,   1,   9,   5,   5],\n",
       "         [  8,   4,  -1,  -2,  -1,  -1,   9,   4,   1],\n",
       "         [  3,   9,   8,   6,   9,  -7,  -5,   1,   4],\n",
       "         [ -9,  -5, -10,   2,   1,   4,   7,  -8,   3],\n",
       "         [  2,   7,  -7,  -8,  -9,   7,  -6,   5,   4],\n",
       "         [ -7,  -6,   7,  -8,  -8,  -6,   6,   7,  -6],\n",
       "         [  6,  -3,  -2,   7,  -9,   4,   0,   5,   8],\n",
       "         [  4,   8,   6,  -2,   2,   7,   4,   9,   3],\n",
       "         [  7,   3,   6,   8,  -2,  -6,   4,  -3,   3],\n",
       "         [-10,  -1,  -2,   6,  -7,  -7,  -4,  -3,   6],\n",
       "         [ -1,   4, -10,   4,   7,  -3,  -8,  -7,   4],\n",
       "         [ -5,   9,   9,  -6,  -8,   5,   6,   2,   5],\n",
       "         [ -1,   7,  -4,  -7,  -4,   1,   8,   7,  -1],\n",
       "         [ -4,   5,  -1,   2,   1,  -6,  -5,  -3,  -1],\n",
       "         [ -5,   3,   9,  -2,  -1,   0,   4,   6, -10],\n",
       "         [  7,   0,  -7,  -4,  -1,  -9,   0,  -1,   6],\n",
       "         [  6,   7,  -2,   4,   9,   5,  -9,   3,  -9],\n",
       "         [-10,   5,   0,   5,   8,   8,   2, -10,  -7],\n",
       "         [ -2,  -4,   6,  -1,   6,   2,  -3,   5,   9],\n",
       "         [ -9,  -2,   3,   4,   4,  -3,   5,   1,   2]]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = H * D\n",
    "w_in = torch.randint(-10, 10, (C, 4*C)) \n",
    "w_out = torch.randint(-10, 10, (4*C, C))\n",
    "w_in, w_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4x9 and 36x9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m expected_mlp \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(actual, w_in, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m# (B, T, C)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m actual_mlp \u001b[38;5;241m=\u001b[39m einsum(actual, w_in, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb t c1, c1 c2  -> b t c2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x9 and 36x9)"
     ]
    }
   ],
   "source": [
    "expected_mlp = F.linear(actual, w_in.T, bias=None) # (B, T, C)\n",
    "actual_mlp = einsum(actual, w_in, 'b t c1, c1 c2  -> b t c2') # (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
