{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clankur/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model import GptLanguageModel\n",
    "from common import GptConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = GptConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GptLanguageModel(hyperparameters)\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "m = model.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = m.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_str = \"\"\"Once upon a time there was a pumpkin. It was a very special pumpkin, it could speak. \n",
    "It was sad because it couldn't move. Every day, it would say\"\"\"\n",
    "encoded_input = tokenizer.encode(start_str)\n",
    "idx = torch.tensor(encoded_input, dtype=torch.long, device=model.device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a pumpkin. It was a very special pumpkin, it could speak. \n",
      "It was sad because it couldn't move. Every day, it would say goodbye and be safe and safe to others.  It never got lost.\n",
      "It always remembered that it was about being brave, like a big pumpkin, who lived on it! Every time he was very careful when she played and make sure everyone around the flower. They laughed so high, and it always stayed safe forever forever forever in the future - it was the best day to have fun with the pumpkin! The end!\n",
      "And it and the pumpkin were the most happy, so lucky to have someone else a safe world around it together and the sun.   It knew that the best day of being kind and helping people could be safe and safe and help everyone. \n",
      "\n",
      " the town knew it was very good to have something new. They were the best way and they all knew the day to be friends and never let the flower come away again and no more knew how much they had to worry. And the end was no longer lonely because of being kind to each other! The pumpkin and its friends stayed friends for days, until their day was over to have lots. The pumpkin learned\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(m.generate(idx = idx, max_new_tokens=model.block_size-len(encoded_input))[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9497, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from common import TinyStoriesLoader\n",
    "\n",
    "# evaluate the model on validation dataset\n",
    "model.eval()\n",
    "validation_set = TinyStoriesLoader(hyperparameters, split='validation')\n",
    "with torch.no_grad():\n",
    "    val_loss = 0\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            inputs = next(validation_set)\n",
    "            xb, yb = inputs['input_ids'][:, :-1], inputs['input_ids'][:, 1:]\n",
    "            logits, loss, _ = model(xb.to(m.device), yb.to(m.device))\n",
    "            val_loss += loss\n",
    "            i += 1\n",
    "        except StopIteration:\n",
    "            break       \n",
    "    print(val_loss / i) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_str = \"\"\"Once upon a time there was a boy named Gin. He was a very big guy\"\"\"\n",
    "encoded_input = tokenizer.encode(start_str)\n",
    "idx = torch.tensor(encoded_input, dtype=torch.long, device=model.device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a boy named Gin. He was a very big guy with a smile and he wanted something very good to eat.\n",
      "He took his friend and said to him, 'This will be so tasty,' he said with a little hug on. He ran around looking in awe and he felt like it seemed very nice to go. Suddenly his friend Jack heard the voice again! She was so excited!  They were so excited that their friend said 'I am going for an hour!\" They laughed, but soon their mom came and asked if she had enough.\n",
      "The little buddy said yes! He ran to the car, excited to go on the way home he had done something. But he forgot to be very sorry for his mom.\n",
      "The man looked at the boy and smiled. It felt like the boy had been very kind, and the man said 'I will come and visit your new one!'\n",
      "\n",
      "Mama hugged his back. The man hugged his son and they both smiled and went back to the same restaurant to enjoy his day with his friends and family, happy. From that the next place was their favorite place to have a new home. The boy knew it's good, but also so important that everyone can make things happen.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tokenizer.decode(m.generate(idx = idx, max_new_tokens=model.block_size-len(encoded_input))[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
