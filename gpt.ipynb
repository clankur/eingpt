{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NanoGPTLangugageModel as nano\n",
    "device = nano.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nano.NanoGPTLanguageModel()\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "m = model.to(nano.device)\n",
    "encode, decode = nano.encode, nano.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theeeeeet-nis, and, eabish; se thag we\n",
      "I\n",
      "I!\n",
      "GLULICIrI\n",
      "Lork:\n",
      "An t sour for tblly kee qors tone ror'd,\n",
      "I I mo yor wath\n",
      "BEome the tot sius mis figese chat,\n",
      "A tha there fore ie\n",
      "I, say our matn wotte foir nd, timy\n",
      "B he me the my y fean;\n",
      "I sr'wid ad, yuct frile detiret!\n",
      "Rwe mer.\n",
      "WIFat IRGi'dethe wThe\n",
      "CKI\n",
      "Hest gow to le ther thene not\n",
      "Merd come that!\n",
      "My four, heu piss whe? pre maws Mou bone\n",
      "The\n",
      "Khe thatsin, the le, beatl\n",
      "\n",
      "LANCLININNBNT: I:\n",
      "Tho seener migh s,\n",
      "Thit\n",
      "To vos a tror you for.\n",
      "Lorvove bot se\n",
      "Sove\n"
     ]
    }
   ],
   "source": [
    "start_str = \"The\"\n",
    "idx = torch.tensor(encode(start_str), dtype=torch.long, device=device).unsqueeze(0)\n",
    "print(decode(m.generate(idx = idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.arange(0, 24)\n",
    "k = torch.arange(0, 24) \n",
    "v = torch.arange(0, 24) + 6\n",
    "q, k, v = [torch.reshape(x, (2, 2, 6)) for x in (q, k, v)] # B, T, C\n",
    "q, k, v = [torch.reshape(x*1.0, (2, 2, 2, 3)) for x in (q, k, v)] # B, T, n, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[12., 13., 14.],\n",
       "          [15., 16., 17.]],\n",
       "\n",
       "         [[12., 13., 14.],\n",
       "          [15., 16., 17.]]],\n",
       "\n",
       "\n",
       "        [[[24., 25., 26.],\n",
       "          [27., 28., 29.]],\n",
       "\n",
       "         [[24., 25., 26.],\n",
       "          [27., 28., 29.]]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.einsum('bqnh,bknh->bqkn', q, k) # B, Q, K, n\n",
    "wei = F.softmax(wei, dim=-2)\n",
    "out = torch.einsum('bqkn,bknh->bqnh', wei, v) # B, n, Q, h\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[12., 13., 14.],\n",
       "          [12., 13., 14.]],\n",
       "\n",
       "         [[15., 16., 17.],\n",
       "          [15., 16., 17.]]],\n",
       "\n",
       "\n",
       "        [[[24., 25., 26.],\n",
       "          [24., 25., 26.]],\n",
       "\n",
       "         [[27., 28., 29.],\n",
       "          [27., 28., 29.]]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = [torch.transpose(x, 1, 2) for x in (q, k, v)] # B, n, T, h\n",
    "wei = torch.einsum('bnqh,bnkh->bnqk', q, k) # B, n, Q, K\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "out = torch.einsum('bnqk,bnkh->bnqh', wei, v) # B, n, Q, h\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.5230e-08, 5.3802e-32],\n",
       "          [      -inf, 1.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00],\n",
       "          [      -inf, 1.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[0.0000e+00, 0.0000e+00],\n",
       "          [      -inf, 1.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00],\n",
       "          [      -inf, 1.0000e+00]]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.trill experiment\n",
    "seq_len = wei.size(1)\n",
    "tril = torch.tril(torch.ones((2, 2), dtype=torch.bool))\n",
    "mask = torch.tril(torch.ones(1, 1, seq_len, seq_len), diagonal=-1).bool()\n",
    "wei = wei.masked_fill(mask, float('-inf'))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kv None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0878, -0.8563, -1.2750, -0.4616,  0.2869,  0.3481],\n",
       "         [-2.2091,  0.7530, -2.7333,  0.5489,  0.4862,  0.2492]],\n",
       "\n",
       "        [[ 0.1010, -0.6038, -0.5472,  0.2571, -1.4411, -0.3963],\n",
       "         [-1.2021, -0.6591,  1.5243,  1.4766, -0.2685, -0.5460]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadAttention (torch.nn.Module):\n",
    "    def __init__ (self, num_heads, embed_dim):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward (self, x, kvcache):\n",
    "        kvcache = (torch.randn(2, 2, 6), torch.randn(2, 2, 6))\n",
    "        print(\"kv\", kvcache)\n",
    "        return x\n",
    "class Block (torch.nn.Module):\n",
    "    def __init__ (self):\n",
    "        super().__init__()\n",
    "        self.sa_heads = MultiHeadAttention(num_heads=4, embed_dim=6)\n",
    "        self.kvcache = None\n",
    "    def forward (self, x):\n",
    "        x = self.sa_heads(x, self.kvcache)\n",
    "        print(\"kv\", self.kvcache)\n",
    "        return x\n",
    "b = Block()\n",
    "b(torch.randn(2, 2, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
