{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NanoGPTLangugageModel as nano\n",
    "device = nano.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nano.NanoGPTLanguageModel()\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "m = model.to(nano.device)\n",
    "encode, decode = nano.encode, nano.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theeeeeet-nis, and, eabish; se thag we\n",
      "I\n",
      "I!\n",
      "GLULICIrI\n",
      "Lork:\n",
      "An t sour for tblly kee qors tone ror'd,\n",
      "I I mo yor wath\n",
      "BEome the tot sius mis figese chat,\n",
      "A tha there fore ie\n",
      "I, say our matn wotte foir nd, timy\n",
      "B he me the my y fean;\n",
      "I sr'wid ad, yuct frile detiret!\n",
      "Rwe mer.\n",
      "WIFat IRGi'dethe wThe\n",
      "CKI\n",
      "Hest gow to le ther thene not\n",
      "Merd come that!\n",
      "My four, heu piss whe? pre maws Mou bone\n",
      "The\n",
      "Khe thatsin, the le, beatl\n",
      "\n",
      "LANCLININNBNT: I:\n",
      "Tho seener migh s,\n",
      "Thit\n",
      "To vos a tror you for.\n",
      "Lorvove bot se\n",
      "Sove\n"
     ]
    }
   ],
   "source": [
    "start_str = \"The\"\n",
    "idx = torch.tensor(encode(start_str), dtype=torch.long, device=device).unsqueeze(0)\n",
    "print(decode(m.generate(idx = idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.arange(0, 24)\n",
    "k = torch.arange(0, 24) \n",
    "v = torch.arange(0, 24) + 6\n",
    "q, k, v = [torch.reshape(x, (2, 2, 6)) for x in (q, k, v)] # B, T, C\n",
    "q, k, v = [torch.reshape(x*1.0, (2, 2, 2, 3)) for x in (q, k, v)] # B, T, n, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[12., 13., 14.],\n",
       "          [15., 16., 17.]],\n",
       "\n",
       "         [[12., 13., 14.],\n",
       "          [15., 16., 17.]]],\n",
       "\n",
       "\n",
       "        [[[24., 25., 26.],\n",
       "          [27., 28., 29.]],\n",
       "\n",
       "         [[24., 25., 26.],\n",
       "          [27., 28., 29.]]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.einsum('bqnh,bknh->bqkn', q, k) # B, Q, K, n\n",
    "wei = F.softmax(wei, dim=-2)\n",
    "out = torch.einsum('bqkn,bknh->bqnh', wei, v) # B, n, Q, h\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[12., 13., 14.],\n",
       "          [12., 13., 14.]],\n",
       "\n",
       "         [[15., 16., 17.],\n",
       "          [15., 16., 17.]]],\n",
       "\n",
       "\n",
       "        [[[24., 25., 26.],\n",
       "          [24., 25., 26.]],\n",
       "\n",
       "         [[27., 28., 29.],\n",
       "          [27., 28., 29.]]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = [torch.transpose(x, 1, 2) for x in (q, k, v)] # B, n, T, h\n",
    "wei = torch.einsum('bnqh,bnkh->bnqk', q, k) # B, n, Q, K\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "out = torch.einsum('bnqk,bnkh->bnqh', wei, v) # B, n, Q, h\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ True, False],\n",
       "         [ True,  True]]),\n",
       " tensor([[[[1.5230e-08, 1.0000e+00],\n",
       "           [0.0000e+00, 1.0000e+00]],\n",
       " \n",
       "          [[5.3802e-32, 1.0000e+00],\n",
       "           [0.0000e+00, 1.0000e+00]]],\n",
       " \n",
       " \n",
       "         [[[0.0000e+00, 1.0000e+00],\n",
       "           [0.0000e+00, 1.0000e+00]],\n",
       " \n",
       "          [[0.0000e+00, 1.0000e+00],\n",
       "           [0.0000e+00, 1.0000e+00]]]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.trill experiment\n",
    "seq_len = wei.size(1)\n",
    "tril = torch.tril(torch.ones((2, 2), dtype=torch.bool))\n",
    "mask = torch.tril(torch.ones(1, 1, seq_len, seq_len), diagonal=-1).bool()\n",
    "\n",
    "tril, wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
