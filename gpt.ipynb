{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/miniconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from model import GptLanguageModel\n",
    "from common import GptConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = GptConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GptLanguageModel(hyperparameters)\n",
    "model.load_state_dict(torch.load('model_weights.pth', map_location=torch.device('cpu')))\n",
    "m = model.to(model.device)\n",
    "tokenizer = m.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_str = \"\"\"Once upon a time there was a pumpkin. It was a very special pumpkin, it could speak. \n",
    "It was sad because it couldn't move. Every day, it would say\"\"\"\n",
    "encoded_input = tokenizer.encode(start_str)\n",
    "idx = torch.tensor(encoded_input, dtype=torch.long, device=model.device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a pumpkin. It was a very special pumpkin, it could speak. \n",
      "It was sad because it couldn't move. Every day, it would say, �™mower! We should take turns. It would go very long to the garden and it could not be very well for everyone to do it. Everyone in town was happy, the pumpkin had so much joy to learn more and learn how. It kept its special day. Everyone had fun with its new glove. The red pumpkin was always happy, because the pumpkin knew what would make her very proud of. The moral value that the story has a special story, and that everyone will love the pumpkin forever. And it was never ever alone again - the end to the world and the special pumpkin.\n",
      "Everyone had so glad to be able on life to be happy, because the old flower had always been so kind and generous! And the little village happy ending to have made it happy, and everyone loved it.\n",
      "It had learned how important the pumpkin was. The End of that day. And from it was always happy.  \n",
      "The little boy knew how important this special day, but no one ever knew it could do the special thing, even though it was the best\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(m.generate(idx = idx, max_new_tokens=model.block_size-len(encoded_input))[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from common import TinyStoriesLoader, compute_perplexity\n",
    "validation_set = TinyStoriesLoader(hyperparameters, split='validation')\n",
    "print(compute_perplexity(m, validation_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained('roneneldan/TinyStories-33M')\n",
    "validation_set = TinyStoriesLoader(hyperparameters, split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_perplexity(model, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_str = \"\"\"Once upon a time there was a boy named Gin. He was a very big guy\"\"\"\n",
    "encoded_input = tokenizer.encode(start_str)\n",
    "idx = torch.tensor(encoded_input, dtype=torch.long, device=model.device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a boy named Gin. He was a very big guy and was playing near the sky! Suddenly the clouds got darker and darker, there could hear a loud noise coming out from outside. The wind made it go away, and everyone started the wind blowing through it.\n",
      "But the wind came in a bad way and everyone could not. They all started playing. Everyone was scared and the boy didn's work away. The rain got louder than ever and faster. The wind made his friends smile as she moved around in their arms as fast until they could play with the storm! They were very scared of their adventure and started the wind to get away too.\n",
      "They ran until their rain was all away and they ran around, feeling safe in the rain again. After the storm was time, everyone had a lot to go to the hospital to stay safe, because they knew they were ready for their visit to go back. The storm was a special journey, so they had to stay in the storm. The little person had to stay with them for themselves, no matter how hard, they had to go and play with the rain and the wind was still. They all agreed of joy that the rain stayed together until they could go again and play. The\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(m.generate(idx = idx, max_new_tokens=model.block_size-len(encoded_input))[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
