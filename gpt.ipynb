{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import GptLanguageModel\n",
    "from NanoGPTLangugageModel import NanoGPTLanguageModel\n",
    "from common import encode, decode, GptConfig, lp_hyperparameters\n",
    "from einops import rearrange, einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = GptConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GptLanguageModel(hyperparameters)\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "m = model.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sirrah, I would touch that murdered?\n",
      "\n",
      "RICHARD:\n",
      "Petir, and thy good sovereign.\n",
      "\n",
      "RATCLIFF:\n",
      "That friend from to-the inform worthy brother.\n",
      "\n",
      "EDWARD:\n",
      "Nay! Forguring and Edward cousin!\n",
      "\n",
      "LADY GREY:\n",
      "So you Hold Gaunt Somerset, grief; from they should\n",
      "That muny fri\n"
     ]
    }
   ],
   "source": [
    "start_str = \"\\n\"\n",
    "idx = torch.tensor(encode(start_str), dtype=torch.long, device=model.device).unsqueeze(0)\n",
    "print(decode(m.generate(idx = idx, max_new_tokens=model.block_size)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state_dict_to_nano(nano_model, gpt_state_dict):\n",
    "  \"\"\"\n",
    "  Converts a state_dict from an Einops model to a format compatible with the nano_model.\n",
    "\n",
    "  Args:\n",
    "    nano_model: The nano model you want to convert the state_dict to.\n",
    "    gpt_state_dict: The state_dict from the Einops model.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary containing the converted state_dict for the nano model.\n",
    "  \"\"\"\n",
    "  nano_state_dict = nano_model.state_dict()\n",
    "  n_head = hyperparameters.n_head\n",
    "\n",
    "  # Copy over the parameters that don't need to be transformed\n",
    "  for param in ['token_embedding_table.weight', 'position_embedding_table.weight', 'lm_head.weight']:\n",
    "    field = param.split('.')[0]\n",
    "    if param == 'lm_head.weight':\n",
    "      nano_state_dict[param] = gpt_state_dict[field].T  # Convert from Einops format\n",
    "    else:\n",
    "      nano_state_dict[param] = gpt_state_dict[field]\n",
    "\n",
    "  # Transform parameters for the blocks\n",
    "  for i in range(hyperparameters.n_layer):\n",
    "    block_prefix = f'blocks.{i}.'\n",
    "    \n",
    "    # Attention weights\n",
    "    att_kvq = gpt_state_dict['attention_kvq'][i]\n",
    "    key_weight, value_weight, query_weight = rearrange(att_kvq, \"s c h d -> s c (h d)\", h=n_head)\n",
    "\n",
    "    nano_state_dict[block_prefix + 'sa_heads.key.weight'] = key_weight.T\n",
    "    nano_state_dict[block_prefix + 'sa_heads.value.weight'] = value_weight.T\n",
    "    nano_state_dict[block_prefix + 'sa_heads.query.weight'] = query_weight.T\n",
    "    nano_state_dict[block_prefix + 'sa_heads.proj.weight'] = gpt_state_dict['out_proj'][i] \n",
    "\n",
    "    # Feedforward network weights and biases\n",
    "    nano_state_dict[block_prefix + 'ffwd.net.0.weight'] = gpt_state_dict['w_in'][i].T\n",
    "    nano_state_dict[block_prefix + 'ffwd.net.2.weight'] = gpt_state_dict['w_out'][i].T\n",
    "\n",
    "  return nano_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NanoGPTLanguageModel(hyperparameters)\n",
    "model.load_state_dict(convert_state_dict_to_nano(model, torch.load('model_weights.pth')))\n",
    "m = model.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Secernatory with it it, and my candition\n",
      "While we doubt it discontent it touche feeble.\n",
      "\n",
      "Third Citizens:\n",
      "We are time the confingel of proof this: and\n",
      "to give stood write in this man belly,\n",
      "That you do move the chance of the encounter's\n",
      "Marriage.\n",
      "\n",
      "FRIAR LAU\n"
     ]
    }
   ],
   "source": [
    "start_str = \"\\n\"\n",
    "idx = torch.tensor(encode(start_str), dtype=torch.long, device=model.device).unsqueeze(0)\n",
    "print(decode(m.generate(idx = idx, max_new_tokens=model.block_size)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix mult using einsum w/ B H T D tensor\n",
    "torch.manual_seed(1337)\n",
    "B, H, T, D = 1, 3, 4, 3\n",
    "out = torch.randint(-10, 10, (B, H, T, D)) # (B, H, T, D)\n",
    "out_proj = torch.randint(-10, 10, (H, D, H*D)) # (H, D, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  5,   7,   2],\n",
       "          [-10,   5,   3],\n",
       "          [  5,   0,   4],\n",
       "          [  0,   2, -10]],\n",
       "\n",
       "         [[  7,  -4,   0],\n",
       "          [  8,   1,  -6],\n",
       "          [ -1,   5,   3],\n",
       "          [ -4,  -8,   0]],\n",
       "\n",
       "         [[ -8,  -9,   6],\n",
       "          [  5,  -1,  -6],\n",
       "          [  5,   9,  -4],\n",
       "          [ -1,   9,   9]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_cache = out\n",
    "K_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  5,   7,   2],\n",
       "          [-10,   5,   3],\n",
       "          [  5,   0,   4],\n",
       "          [  0,   2, -10]],\n",
       "\n",
       "         [[  7,  -4,   0],\n",
       "          [  8,   1,  -6],\n",
       "          [ -1,   5,   3],\n",
       "          [ -4,  -8,   0]],\n",
       "\n",
       "         [[ -8,  -9,   6],\n",
       "          [  5,  -1,  -6],\n",
       "          [  5,   9,  -4],\n",
       "          [ -1,   9,   9]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep the last block_size elements of the sequence in T\n",
    "block_size = 3\n",
    "K_cache = K_cache[:, :, -block_size:, :]\n",
    "K_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-154,  224,  175,   75,  -45,   15,  224,  -18, -100],\n",
       "         [-118,   61,   -8,  180,  -28,   -3,  -33,  -33,  -73],\n",
       "         [ 137, -124,  -38,  -95,  -55,   49, -115,  113,   70],\n",
       "         [  97,    7, -171,   -8,   91,   64,  123, -133, -206]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_proj_T = rearrange(out_proj, 'h d c -> c h d') # this isn't transpose, how to transpose\n",
    "einsum(out, out_proj_T, 'b h t d, c h d -> b t c') # (B, H, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  49,  -97,   53,   34, -107, -146,  158,  -85,  -36],\n",
       "          [ -72,  200,  -70,  175, -162, -143, -112, -187,    6],\n",
       "          [  91,   55,  -38,   38,   30,   39,  -87,   61,   -4],\n",
       "          [  50,   18,   86, -165,   72,  210,  146,  -25, -115]]]),\n",
       " tensor([[[True, True, True, True, True, True, True, True, True],\n",
       "          [True, True, True, True, True, True, True, True, True],\n",
       "          [True, True, True, True, True, True, True, True, True],\n",
       "          [True, True, True, True, True, True, True, True, True]]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_out = rearrange(out, 'b h t d -> b t (h d)') # (B, T, C)\n",
    "new_out_proj = rearrange(out_proj, 'h d c -> (h d) c') # (C, C)\n",
    "new_out_proj_T = new_out_proj.T\n",
    "\n",
    "expected = F.linear(new_out, new_out_proj, bias=None) # (B, T, C)\n",
    "actual = einsum(new_out, new_out_proj_T, 'b t c1, c1 c2  -> b t c2') # (B, T, C)\n",
    "actual, expected == actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  7,   3,  -2,   0,  -9,  -8,  -3,   5,   0,  -4,  -1,  -8,   4,   9,\n",
       "           -9,   8, -10,  -7,   1,  -3,  -1,   6,  -9,   5,  -6,   6,   1,   1,\n",
       "            5,  -9,   4,  -1,   2,   5, -10,   3],\n",
       "         [  2,   3,   6,   1,  -5,   4,   9,   5,   0,   4,   5,   4,   9,   5,\n",
       "           -7,  -5,  -4,   1,   4,   4,   3,   6,  -1,  -2,   5,   1,   8,  -6,\n",
       "          -10,  -1,   4,   7,  -4,   1,  -5,   0],\n",
       "         [-10,   4,  -4,  -7,   3,   3,   8,   6,   2,  -5,  -1,   0,   7,  -3,\n",
       "           -9,  -8,  -1,   8,   4,  -7,  -7,  -9,   8,  -5,   1,   5,  -6,  -3,\n",
       "            5,   1,  -2,   4,   2,   0,   4,  -5],\n",
       "         [  2,   8,  -2,   4,  -6,   8,   4,   5,  -8,  -4,  -5, -10,  -5,   4,\n",
       "           -2,   0, -10,   2,   2,  -1,   5,   4,   3,   1,   4,   0,  -1,  -9,\n",
       "            1,   9,   3,  -5,   8,   1,   2,  -3],\n",
       "         [  2,   8,   7,   9,  -4,  -1,  -4,   8,  -4,   3,  -3,  -9,   1,  -2,\n",
       "          -10,   6,   0,   7,  -8,   6,  -6,  -9,  -9,  -9,  -1,  -9,   9,   1,\n",
       "            5,  -9,   2,   6,  -7,   0,   9,   3],\n",
       "         [  4,  -2,  -6,   9,  -8,  -9,  -4,  -3,  -3,   3,  -9,  -4,   0,   7,\n",
       "            5,  -2,   6,  -8, -10,  -5,   6,   6,   0,   7,   4,  -6,   2,   3,\n",
       "            1,   7, -10,   5,   7,   3,  -1,   5],\n",
       "         [  7,  -9,  -3,  -1,  -3,  -5,  -1,   5,   0,  -5,   9,  -6,   5,  -8,\n",
       "            2,  -1,   3,  -7,   9,  -2,   6,   4,   4,   1,   0,   1,   0,   4,\n",
       "           -9,   6,  -4,  -4, -10,   2,  -3,  -4],\n",
       "         [ -6,  -7,   6,   3,  -3,   2,   0,  -7,   7,  -3,   5,  -9,  -7, -10,\n",
       "            0,   5,   1,  -5,  -8,   6,  -5, -10,  -7,  -7,  -5,  -2,   9,  -8,\n",
       "            6,   5,  -5,   1,   0,   3,  -7,  -3],\n",
       "         [ -5,  -8,  -6,  -3,  -4,  -9,   6,   8,   3,   5, -10,  -4,   2,  -5,\n",
       "            9,  -6,  -1,   7,  -3,   7,  -2,  -2,   9, -10,  -6,   6,  -2,  -2,\n",
       "            2,  -1, -10,   1, -10,  -8,  -3,  -9]]),\n",
       " tensor([[ -6,  -8,   0,  -6,  -2,  -7,  -8, -10,  -3],\n",
       "         [ -2,   5,  -2, -10,  -2,  -2,   0,  -1,  -8],\n",
       "         [  6,  -5,  -5,  -6,  -6,   5,   1,  -7,  -1],\n",
       "         [  5,   2,   4,   9,   4,  -7,   3,  -9,  -4],\n",
       "         [  4,   8,   7,  -5,   7,  -6,   7,   2,  -1],\n",
       "         [ -6,   7, -10,  -7,   2,  -2,  -6,  -3,  -6],\n",
       "         [ -9, -10,  -8,  -8,  -4,   2, -10,  -3,   7],\n",
       "         [ -5,   6,   1,  -3,   2,   5,   9,   2,   9],\n",
       "         [  4,  -7,   0,   7,  -6,   1,   7,   9,   0],\n",
       "         [ -4,  -9,   8,   2,  -1,   4,  -6,  -8,  -3],\n",
       "         [  3,  -5,  -6,   2,  -8,  -1,  -1,  -4,   2],\n",
       "         [ -6,   2,   8,   8,   1,  -2,   6,  -8,   5],\n",
       "         [ -7,  -8,  -8,  -9,  -4,  -8,  -6, -10,   1],\n",
       "         [  6,   8,   9,   7,   0,   5,   4,  -7,  -9],\n",
       "         [  0,   4,  -5,  -5,  -1,  -8,   2,  -4,   2],\n",
       "         [ -4, -10,  -1,  -8,  -8,  -7,  -8,  -1,  -3],\n",
       "         [  4,  -3,   0,   0,   0,  -8,   9,   0,  -3],\n",
       "         [ -7,  -2,  -6,  -3,   7,   5,  -8,   2,  -4],\n",
       "         [ -1,  -5,   2,  -1,  -4, -10,  -7,   8,   2],\n",
       "         [  5,  -9,  -4,   7,   7,   8,   0,  -3,  -4],\n",
       "         [  9,  -6,  -2,   6, -10,   4,   8,   7,   4],\n",
       "         [  9,  -5,  -4,   3,  -8,  -7,  -2,   8,   8],\n",
       "         [ -8,  -8,   3,  -5,  -4,  -4,   2,  -4,   7],\n",
       "         [ -3,   0,   3,   4,   0,  -2,  -7,  -2,   0],\n",
       "         [  4,  -4,  -8,  -5,   8,   7,  -9,   8,   7],\n",
       "         [ -3,   2, -10,  -8,   0,   5,  -9,   1,   9],\n",
       "         [  1,  -7,  -1,   5,  -1,  -4,  -5,  -4,  -7],\n",
       "         [-10,   0,  -7,  -5,  -2,   4,   2,  -8,  -9],\n",
       "         [  4,  -1,  -3,   9,   8,  -3,   2,   2,   2],\n",
       "         [ -5,   7,  -9,   0,  -2,  -3,   9,  -5,   1],\n",
       "         [ -6, -10,   8,   2,  -4,  -1,   2,  -2,  -2],\n",
       "         [ -9,   0,   3,   9,   0,   0,   8,  -3,   1],\n",
       "         [ -7,  -7,  -8,  -2,  -7,   0,   7,  -4,   5],\n",
       "         [  9,   1,  -8,   9,   9,  -2,   9,  -1,   3],\n",
       "         [  0,   5,   7,   8,   8,  -5,   0,  -9,  -4],\n",
       "         [  4,   9,  -4,   8,   8, -10,  -7,  -4,   2]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = H * D\n",
    "w_in = torch.randint(-10, 10, (C, 4*C)) \n",
    "w_out = torch.randint(-10, 10, (4*C, C))\n",
    "w_in, w_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_mlp = F.linear(actual, w_in.T, bias=None) # (B, T, C)\n",
    "actual_mlp = einsum(actual, w_in, 'b t c1, c1 c2  -> b t c2') # (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
